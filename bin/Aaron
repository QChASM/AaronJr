#!/usr/bin/env python3
import datetime
import itertools as it
import os
import re
from math import exp
from time import sleep
from warnings import warn

from Aaron.job import LAUNCHPAD, Job
from Aaron.results import Results
from AaronTools.config import Config
from AaronTools.const import AARONLIB, PHYSICAL, UNIT
from AaronTools.geometry import Geometry
from AaronTools.utils.utils import progress_bar


def monitor(fw_id, verbose=False, force_rerun=False, dryrun=False):
    """
    Checks status of FW
    :fw_id: the id of the FW
    :verbose: print more details to stdout if true
    :force_rerun: passed to Job.resolve_error() as force_rerun parameter
    """
    workflow = LAUNCHPAD.get_wf_by_fw_id(fw_id)
    fw = LAUNCHPAD.get_fw_by_id(fw_id)
    job = Job(fw)
    job.quiet = not verbose
    if verbose or fw.state not in ["WAITING"]:
        print(
            "{:10} {:10} {} {}".format(
                fw.fw_id, fw.state, job.config["DEFAULT"]["name"], fw.name
            )
        )
    if dryrun:
        return True
    if fw.state in ["RUNNING", "COMPLETED"]:
        try:
            job.transfer_output()
        except FileNotFoundError as e:
            if fw.state == "RUNNING":
                return False
            raise FileNotFoundError(e)
        try:
            output = job.validate()
            if fw.state == "RUNNING":
                progress = output.get_progress()
                if "not found" not in progress:
                    print(progress)
        except OSError as e:
            warn("Issue validating computational output")
            warn(str(e))
            warn("Trying to rerun firework")
            LAUNCHPAD.rerun_fw(fw.fw_id)
            return False
    if fw.state == "COMPLETED":
        for child in workflow.links[fw.fw_id]:
            child = LAUNCHPAD.get_fw_by_id(child)
            if child.state in ["READY", "WAITING"]:
                child = Job(child)
                child.update_structure(output.geometry)
        if not output:
            return False
        if output.finished:
            return True
    if fw.state in ["DEFUSED", "FIZZLED"]:
        if len(fw.archived_launches) > 10:
            return True
        try:
            job.transfer_output()
        except FileNotFoundError as e:
            if fw.state == "FIZZLED":
                LAUNCHPAD.rerun_fw(fw.fw_id)
                return False
            else:
                raise FileNotFoundError(e)
        job.validate()
        job.resolve_error(force_rerun=force_rerun)
    if fw.state == "READY":
        job.write()
        job.launch_job()
    return False


def get_fws(args, template, config, job_type=None):
    if args.command == "run":
        make_structures = True
    else:
        make_structures = False
    all_jobs = []
    all_changes = []
    if not config._changes:
        config._changes = {"": ({}, None)}
    for name, (changes, kind) in config._changes.items():
        if make_structures:
            structure = template.copy()
        else:
            structure = template
        job_name = structure.name
        if kind is not None and name:
            job_name = os.path.join(name, structure.name)
        this_config = config.copy()
        if job_type is not None:
            this_config["Job"]["include"] = job_type
        this_config._parse_includes()
        this_config["Job"]["name"] = job_name
        parent = None
        for i, ac in enumerate(all_changes):
            for c in changes:
                if c in ac and ac[c] == changes[c]:
                    del changes[c]
                    break
            else:
                continue
            parent = all_jobs[i].fw_id
            if make_structures:
                structure.atoms = all_jobs[i].structure.atoms
            break
        this_config._changes = {name: (changes, kind)}
        job = Job(
            structure,
            this_config,
            quiet=args.quiet,
            make_changes=make_structures,
        )
        if make_structures and args.show:
            job.structure.write()
            os.system("chimera {}.xyz".format(job.structure.name))
            print(job.structure)
            ans = input("Starting structure OK? (Y/n) ")
            if ans.lower() in ["n", "no"]:
                exit(2)
        if make_structures:
            job.add_workflow(parent_fw_id=parent)
        else:
            first = True
            for step in job.get_steps():
                job.step = step
                fw = job.find_fw()
                if not fw:
                    continue
                if first:
                    job.set_root(fw.fw_id)
                    first = False
                if args.command == "update":
                    if fw.state == "COMPLETED" and args.force:
                        LAUNCHPAD.defuse_fw(fw.fw_id)
                    LAUNCHPAD.update_spec([fw.fw_id], job._get_metadata())
                    job.validate()
                else:
                    break
        all_changes += [changes]
        all_jobs += [job]
    return all_jobs


def resources(args, all_jobs):
    workflows = set([])
    for job in all_jobs:
        fw = job.find_fw()
        wf = LAUNCHPAD.get_wf_by_fw_id(fw.fw_id)
        workflows.add(wf)

    results = {}
    for wf in sorted(workflows, key=lambda x: sorted(x.name)):
        for fw in sorted(wf.fws, key=lambda x: sorted(x.name)):
            job = Job(fw)
            if fw.state in ["COMPLETED", "DEFUSED"]:
                if args.csv:
                    key = (fw.fw_id, fw.name)
                    results[key] = []
                else:
                    print(fw.fw_id, fw.name)
            for launch in fw.archived_launches + fw.launches:
                if launch.state not in ["COMPLETED", "DEFUSED"]:
                    continue
                data = launch.action.stored_data
                opt_steps = data.get("opt_steps", 0)
                error = data.get("error", "")
                if not error:
                    error = "None"
                for history in launch.state_history:
                    if history["state"] != "RUNNING":
                        continue
                    tdelta = history["updated_on"] - history["created_on"]
                    tdelta = datetime.timedelta(
                        seconds=round(tdelta.total_seconds())
                    )
                    if tdelta.total_seconds() < 5:
                        continue
                    if opt_steps > 1 and args.csv:
                        results[key] += [
                            (
                                launch.launch_id,
                                error,
                                tdelta,
                                opt_steps,
                            )
                        ]
                    elif opt_steps > 1:
                        print(
                            "{:>10d} err:{:<10} {:>10} {:>5d} optimization steps".format(
                                launch.launch_id,
                                error,
                                str(tdelta),
                                opt_steps,
                            )
                        )
                    elif args.csv:
                        results[key] += [(launch.launch_id, error, tdelta)]
                    else:
                        print(
                            "{:>10d} err:{:<10} {:>10}".format(
                                launch.launch_id, error, str(tdelta)
                            )
                        )
        if args.csv:
            csv = [
                [
                    "fw_id",
                    "name",
                    "launch_id",
                    "error",
                    "runtime",
                    "optimization steps",
                ]
            ]
            for key, val in results.items():
                for item in val:
                    csv += [list(key) + list(item)]
            for line in csv:
                print(line)
        else:
            print()


def run(args, all_jobs):
    skip_fws = set([])
    all_fws = set([])
    verbose = not args.quiet
    for job in all_jobs:
        wf = LAUNCHPAD.get_wf_by_fw_id(job.find_fw().fw_id)
        all_fws.update([fw.fw_id for fw in wf.fws])
        if job._root_fw() in all_fws:
            skip_fws.add(job._root_fw())
    first = True
    while len(skip_fws) != len(all_fws):
        for fw_id in all_fws:
            if fw_id in skip_fws:
                continue
            if monitor(
                fw_id, verbose=verbose, force_rerun=first, dryrun=args.dryrun
            ):
                skip_fws.add(fw_id)
        if not verbose:
            try:
                sleep(args.sleep * 60)
            except KeyboardInterrupt:
                exit(0)
        if not args.dryrun:
            os.system("clear")
        verbose = False
        first = False


def main(args):
    config = Config(args.config, quiet=args.quiet)
    config.parse_functions()
    configs = {}
    job_dict = {}

    # parse child config files and store in `configs`
    if "Configs" in config:
        for key in config["Configs"]:
            if key in config["DEFAULT"] or key in ["override"]:
                continue
            configs[key] = []
            for conf in config["Configs"][key].split(","):
                tmp = Config(os.path.relpath(conf), quiet=True)
                for override in config.get(
                    "Configs", "override", fallback=""
                ).split("\n"):
                    if override:
                        k, v = [i.strip() for i in override.split("=")]
                        tmp["DEFAULT"][k] = v
                configs[key] += [tmp]
    else:
        # no children configs, just use args.config
        configs = {
            config["DEFAULT"]["name"]: [Config(args.config, quiet=True)]
        }

    # get fws
    for name, conf_list in configs.items():
        all_jobs = set([])
        for conf in conf_list:
            conf.parse_functions()
            print(conf)
            try:
                template = conf.get_template()
            except FileNotFoundError as e:
                raise e
            if isinstance(template, Geometry):
                all_jobs = get_fws(args, template, conf)
            else:
                for template, kind in conf.get_template():
                    all_jobs.update(
                        get_fws(
                            args,
                            template,
                            conf,
                            job_type=kind,
                        )
                    )
        job_dict[name] = list(all_jobs)

    all_jobs = it.chain.from_iterable(job_dict.values())
    if args.command == "run":
        run(args, list(all_jobs))
    if args.command == "resources":
        resources(args, list(all_jobs))
    if args.command in ["results", "plot"]:
        Results(args, job_dict)


def add_common_arguments(parser):
    parser.add_argument(
        "config",
        nargs="?",
        type=str,
        metavar="path/to/file",
        default="config.ini",
        help="computational configuration file",
    )
    parser.add_argument(
        "--quiet", action="store_true", help="turn off status messages"
    )


def run_arguments(run_parser):
    run_parser.add_argument(
        "--show", action="store_true", help="show structure before submitting"
    )
    run_parser.add_argument(
        "--sleep",
        type=float,
        default=5,
        help="number of minutes to sleep between monitoring cycles (default: 5)",
    )
    run_parser.add_argument(
        "--dryrun",
        action="store_true",
        help="Don't run anything, just make workflow",
    )


def update_arguments(update_parser):
    update_parser.add_argument(
        "--force",
        action="store_true",
        help="Update FW.spec for completed FWs as well (make sure you know what you're doing!)",
    )


def results_arguments(results_parser):
    results_parser.add_argument(
        "--change",
        nargs="*",
        type=str,
        help="The substitution/mapping(s) to show (use 'None' for no change)",
    )
    results_parser.add_argument(
        "--absolute",
        action="store_true",
        help="print absolute energies instead of relative",
    )
    results_parser.add_argument(
        "--unit",
        type=str,
        default="kcal/mol",
        choices={"kcal/mol", "Hartree"},
        help="convert to UNIT",
    )
    results_parser.add_argument(
        "--thermo",
        default="free_energy",
        help="Which thermodynamic quantity to use (default is 'free-energy'=='RRHO')",
        choices=[
            "energy",
            "enthalpy",
            "free_energy",
            "RRHO",
            "QRRHO",
            "QHARM",
        ],
    )
    results_parser.add_argument(
        "--temp",
        type=float,
        default=None,
        help="Temperature (K) to use (if different from config specification)",
    )
    results_parser.add_argument(
        "-w0",
        "--frequency-cutoff",
        type=float,
        default=100.0,
        dest="w0",
        help="cutoff frequency for quasi free energy corrections (1/cm)\nDefault: 100 cm^-1",
    )
    results_parser.add_argument(
        "--cache",
        type=str,
        default="results.cache",
        metavar="FILENAME",
        help="Where to save (if file doesn't exist) / load (if file does exist) cached job output data",
    )
    results_parser.add_argument(
        "--reload",
        action="store_true",
        help="Clear the current cache file and reload output data",
    )
    results_parser.add_argument(
        "--step", type=float, nargs="+", help="Use only data from this step"
    )


def resources_arguments(resources_parser):
    resources_parser.add_argument(
        "--include-failed", action="store_true", help="Include failed jobs"
    )


def plot_arguments(plot_parser):
    plot_parser.add_argument("--title", nargs="*", help="The title(s) to use")
    plot_parser.add_argument(
        "--save", action="store_true", help="Save the plot as CHANGE.tiff"
    )


def output_arguments(command_parser):
    command_parser.add_argument(
        "-csv", "--csv", action="store_true", help="Use csv format"
    )
    command_parser.add_argument(
        "-of",
        "--outfile",
        nargs=1,
        help="Save to file instead of printing to STDOUT",
    )


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        description="For help with a specific command use 'Aaron <command> --help'",
    )

    # Subparsers for commands
    command = parser.add_subparsers(title="commands", dest="command")

    command_parser = command.add_parser(
        "run", help="Run Aaron workflow (default command)"
    )
    add_common_arguments(command_parser)
    run_arguments(command_parser)

    command_parser = command.add_parser(
        "update", help="Update FireWorks metadata"
    )
    add_common_arguments(command_parser)
    update_arguments(command_parser)

    command_parser = command.add_parser(
        "results", help="Show computational results summary"
    )
    add_common_arguments(command_parser)
    results_arguments(command_parser)
    output_arguments(command_parser)

    command_parser = command.add_parser(
        "plot", help="plot reaction energy diagram"
    )
    add_common_arguments(command_parser)
    results_arguments(command_parser)
    plot_arguments(command_parser)

    # 'resources' specific options
    command_parser = command.add_parser(
        "resources", help="Show resource usage summary"
    )
    add_common_arguments(command_parser)
    resources_arguments(command_parser)
    output_arguments(command_parser)

    args = parser.parse_args()
    main(args)
