#!/usr/bin/env python3
import contextlib
import datetime
import io
import itertools as it
import os
import time
from time import sleep

from AaronJr.job import LAUNCHPAD, Job
from AaronJr.results import Results
from AaronTools.config import Config
from fireworks import LaunchPad


def main(args):
    config = Config(args.config, quiet=args.quiet)
    config.parse_functions()
    configs = {}
    job_dict = {}
    if args.command not in ["run", "update"]:
        Job.SKIP_CONNECT = True
    elif args.command == "update" and args.no_xfer:
        Job.SKIP_CONNECT = True
    elif args.command == "run" and args.dryrun:
        Job.SKIP_CONNECT = True

    # parse child config files and store in `configs`
    if "Configs" in config:
        for key in config["Configs"]:
            if key in config["DEFAULT"] or key in ["override"]:
                continue
            configs[key] = []
            for this_config in config["Configs"][key].split("\n"):
                tmp = Config(os.path.relpath(this_config), quiet=True)
                for override in config.get(
                    "Configs", "override", fallback=""
                ).split("\n"):
                    if override:
                        k, v = [i.strip() for i in override.split("=")]
                        tmp.set("DEFAULT", k, v)
                configs[key] += [tmp]
    else:
        # no children configs, just use args.config
        configs = {
            config["DEFAULT"]["name"]: [Config(args.config, quiet=True)]
        }

    # get fws
    for name, conf_list in sorted(configs.items(), key=lambda x: x[0]):
        all_jobs = set([])
        for this_config in conf_list:
            try:
                template = this_config.get_template()
            except FileNotFoundError as e:
                raise e
            for template, kind in sorted(
                this_config.get_template(), key=lambda x: (x[1], x[0].name)
            ):
                if not args.quiet:
                    print(
                        "Loading jobs ({})... {}".format(
                            this_config["DEFAULT"]["name"], template.name
                        )
                        + " " * 50,
                        end="\r",
                    )
                all_jobs.update(get_fws(args, template, this_config))
            if args.command not in ["run", "update"]:
                # calling the 'update' method already gets conformers
                # AND creates workflows for new conformers discovered during
                # validation. This other way of getting conformers is only for
                # conformers already present in the workflow (thus, this section
                # is appropriate for `results` and `resources` commands)
                conformers = set([])
                for job in all_jobs:
                    if job.fw_id is None:
                        continue
                    conf_job = {}
                    children = LAUNCHPAD.get_wf_by_fw_id_lzyfw(job.fw_id)
                    for child in children.fws:
                        try:
                            n_conf = child.spec["conformer"]
                        except KeyError:
                            # these are root fws
                            continue
                        if n_conf == 0:
                            continue
                        if n_conf in conf_job:
                            # one job for all steps
                            continue
                        conf_job[n_conf] = Job(child, this_config)
                    conformers.update(conf_job.values())
                all_jobs.update(conformers)
            if not args.quiet:
                print(
                    "Loading jobs ({})... {}".format(
                        this_config["DEFAULT"]["name"], "Done"
                    )
                    + " " * 50,
                )
        all_jobs = sorted(all_jobs, key=lambda x: x.jobname)
        job_dict[name] = all_jobs

    all_jobs = set(it.chain.from_iterable(job_dict.values()))
    all_jobs = sorted(all_jobs, key=lambda x: x.jobname)
    if args.command == "run":
        fw_jobs = update(args, all_jobs)
        run(args, fw_jobs)
    if args.command == "update":
        fws = update(args, all_jobs)
        if args.print_spec:
            for fw in fws:
                print(fw.spec)
    if args.command == "resources":
        resources(args, all_jobs)
    if args.command in ["results", "plot"]:
        Results(args, job_dict)


# command methods
def resources(args, all_jobs):
    workflows = set([])
    for job in all_jobs:
        fw = job.find_fw()
        wf = LAUNCHPAD.get_wf_by_fw_id(fw.fw_id)
        workflows.add((wf, job.config))

    results = {}
    for wf, config in sorted(workflows, key=lambda x: sorted(x[0].name)):
        for fw in sorted(wf.fws, key=lambda x: sorted(x.name)):
            job = Job(fw, config=config)
            if fw.state in ["COMPLETED", "DEFUSED"]:
                if args.csv:
                    key = (fw.fw_id, fw.name)
                    results[key] = []
                else:
                    print(fw.fw_id, fw.name)
            for launch in fw.archived_launches + fw.launches:
                if launch.state not in ["COMPLETED", "DEFUSED"]:
                    continue
                data = launch.action.stored_data
                opt_steps = data.get("opt_steps", 0)
                error = data.get("error", "")
                if not error:
                    error = "None"
                for history in launch.state_history:
                    tdelta = None
                    state = history["state"]
                    if history["state"] == "RUNNING":
                        tdelta = history["updated_on"] - history["created_on"]
                        tdelta = datetime.timedelta(
                            seconds=round(tdelta.total_seconds())
                        )
                    elif history["state"] == "RESERVED":
                        tdelta = history["updated_on"] - history["created_on"]
                        tdelta = datetime.timedelta(
                            seconds=round(tdelta.total_seconds())
                        )
                    else:
                        continue

                    if state == "RUNNING" and opt_steps > 0 and args.csv:
                        results[key] += [
                            (
                                launch.launch_id,
                                state,
                                error,
                                tdelta,
                                opt_steps,
                            )
                        ]
                    elif state == "RUNNING" and opt_steps > 0:
                        print(
                            "{:>10d} state:{:<10} err:{:<10} {:>10} {:>5d} optimization steps".format(
                                launch.launch_id,
                                state,
                                error,
                                str(tdelta),
                                opt_steps,
                            )
                        )
                    elif args.csv:
                        results[key] += [
                            (launch.launch_id, state, error, tdelta)
                        ]
                    else:
                        print(
                            "{:>10d} state:{:<10} err:{:<10} {:>10}".format(
                                launch.launch_id,
                                state,
                                error,
                                str(tdelta),
                            )
                        )
        if args.csv:
            csv = [
                [
                    "fw_id",
                    "name",
                    "launch_id",
                    "state",
                    "error",
                    "tdelta",
                    "optimization steps",
                ]
            ]
            for key, val in results.items():
                for item in val:
                    csv += [list(key) + list(item)]
            for line in csv:
                print(line)
        else:
            print()


def run(args, fw_jobs):
    first = True
    while fw_jobs:
        if not first and args.dryrun:
            exit()
        if not args.dryrun:
            os.system("clear")
        skip = set([])
        found_new_children = False
        children = {}
        for fw_id, job in fw_jobs.items():
            job.set_fw(fw_id=fw_id)
            res = monitor(job, force_rerun=first, dryrun=args.dryrun)
            if res:
                skip.add(fw_id)
            else:
                continue
            workflow = LAUNCHPAD.get_wf_by_fw_id(fw_id)
            for child_id in workflow.links[fw_id]:
                if child_id not in fw_jobs:
                    found_new_children = True
                    child_fw = LAUNCHPAD.get_fw_by_id(child_id)
                    children[child_id] = Job(child_fw, job.config)
        for child_id, child_job in children.items():
            fw_jobs[child_id] = child_job
        for s in skip:
            del fw_jobs[s]
        first = False or found_new_children
        if first:
            continue
        if args.dryrun or not fw_jobs:
            exit(0)
        try:
            print_countdown(args.sleep, msg="Sleeping... ({:02}:{:02})   ")
        except KeyboardInterrupt:
            exit(0)


def update(args, all_jobs):
    """
    Returns:
        dict fw_jobs, where fw_jobs[fw_id] = job
    """
    fw_jobs = {}
    if hasattr(args, "no_xfer"):
        no_xfer = getattr(args, "no_xfer")
    elif hasattr(args, "dryrun"):
        no_xfer = getattr(args, "dryrun")
    else:
        no_xfer = False
    done = set()
    for job in all_jobs:
        wf, _ = job.add_workflow()
        wf = sorted(set(wf) - done)
        while wf:
            fw_id = wf[0]
            fw = LAUNCHPAD.get_fw_by_id(fw_id)
            print(
                "Checking job {} ...".format(fw.name),
                end="\r",
            )
            try:
                job.load_fw(fw)
                fw_jobs[fw.fw_id] = job
                capture = io.StringIO()
                with contextlib.redirect_stdout(capture):
                    job.validate(
                        update=(args.command == "update"),
                        transfer=(not no_xfer),
                    )
                fw = LAUNCHPAD.get_fw_by_id(fw_id)
            except Exception:
                # this essentially turns the end="\r" of the previous print cmd to \n
                # otherwise the traceback will overwrite the "Checking job..." message
                print()
                raise
            print("Checking job {} {}".format(fw.name, fw.state))
            print(capture.getvalue(), end="")
            # make sure any children that only became apparent after validation
            # are included in update loop (eg: conformer children don't get added
            # until after validation)
            done.add(fw_id)
            done.add(job.root_fw_id)
            updated_wf = LAUNCHPAD.get_wf_by_fw_id_lzyfw(fw_id)
            updated_wf = set(fw.fw_id for fw in updated_wf.fws)
            wf = sorted(updated_wf.union(wf) - done)
    return fw_jobs


# utility methods
def monitor(job, verbose=False, force_rerun=False, dryrun=False):
    """
    Checks status of FW
    :fw_id: the id of the FW
    :verbose: print more details to stdout if true
    :force_rerun: passed to Job.resolve_error() as force_rerun parameter
    """
    job.quiet = not verbose
    try:
        output = job.validate(transfer=not dryrun)
    except IndexError:
        if dryrun:
            output = None
        else:
            raise

    fw = LAUNCHPAD.get_fw_by_id(job.fw_id)
    if verbose or fw.state not in ["WAITING"]:
        print(
            "{:9}{: 9} {} {}".format(
                fw.state,
                fw.fw_id,
                job.config["DEFAULT"]["name"],
                fw.name,
            )
        )
    if dryrun:
        return True
    if fw.state == "READY":
        job.launch_job()
        return False
    if fw.state == "RUNNING" and output is not None:
        progress = output.get_progress()
        if "not found" not in progress:
            print("  %s" % progress)
        return False
    if fw.state == "COMPLETED":
        return True
    if fw.state in ["DEFUSED", "FIZZLED"]:
        if job.resolve_error(force_rerun=force_rerun):
            job.launch_job()
    return False


def get_fws(args, template, config):
    """
    Returns: list(Job) associated with template and config
    """
    all_jobs = []
    all_changes = []
    if not config._changes:
        config._changes = {"": ({}, None)}
    for name, (changes, kind) in sorted(
        config._changes.items(), key=lambda x: x[0]
    ):
        structure = template.copy()
        this_config = config.for_change(name, structure=structure)
        parent = None
        for i, ac in enumerate(all_changes):
            for c in changes:
                if c in ac and ac[c] == changes[c]:
                    del changes[c]
                    break
            else:
                continue
            parent = all_jobs[i].fw_id
            structure.atoms = all_jobs[i].structure.atoms
            break
        structure = this_config.make_changes(structure)
        job = Job(
            structure,
            config=this_config,
            quiet=args.quiet,
            make_root=(args.command in ["update", "run"]),
        )
        if hasattr(args, "show") and args.show:
            job.structure.write()
            os.system("chimerax {}.xyz".format(job.structure.name))
            print(job.structure)
            ans = input("Starting structure OK? (Y/n) ")
            if ans.lower() in ["n", "no"]:
                exit(2)
        if args.command in ["update", "run"]:
            job.add_workflow(parent_fw_id=parent)
        else:
            for step in job.get_steps():
                fw = job.set_fw(step=step)
                if not fw:
                    continue
        all_changes += [changes]
        all_jobs += [job]
    return all_jobs


def print_countdown(minutes, msg="{: 2}:{:02}"):
    now = datetime.datetime.now
    end = now() + datetime.timedelta(minutes=minutes)
    while True:
        if now() > end:
            break
        seconds = datetime.timedelta.total_seconds(end - now())
        minutes = seconds // 60
        seconds = round(seconds % 60, 0)
        print(msg.format(int(minutes), int(seconds)), end="\r")
        sleep(1)


# argument handling
def add_common_arguments(parser):
    parser.add_argument(
        "config",
        nargs="?",
        type=str,
        metavar="path/to/file",
        default="config.ini",
        help="computational configuration file",
    )
    parser.add_argument(
        "--quiet", action="store_true", help="turn off status messages"
    )


def run_arguments(run_parser):
    run_parser.add_argument(
        "--show", action="store_true", help="show structure before submitting"
    )
    run_parser.add_argument(
        "--sleep",
        type=float,
        default=5,
        help="number of minutes to sleep between monitoring cycles (default: 5)",
    )
    run_parser.add_argument(
        "--dryrun",
        action="store_true",
        help="Don't run anything, just make workflow and check statuses. Will not transfer from remote host before checking.",
    )


def update_arguments(update_parser):
    update_parser.add_argument("--print_spec", action="store_true", help="")
    update_parser.add_argument(
        "--no-xfer",
        action="store_true",
        help="Don't transfer files from remote HPC",
    )


def resources_arguments(resources_parser):
    resources_parser.add_argument(
        "--include-failed", action="store_true", help="Include failed jobs"
    )


def results_arguments(results_parser):
    results_parser.add_argument(
        "--script",
        nargs="*",
        type=str,
        help="Pass geometries through an AaronTools command line script. eg: --script 'bond.py -m 1 2' (note the single quotes!)",
    )
    results_parser.add_argument(
        "--change",
        nargs="*",
        type=str,
        help="The substitution/mapping(s) to show (use 'None' for no change)",
    )
    results_parser.add_argument(
        "--absolute",
        action="store_true",
        help="print absolute energies instead of relative",
    )
    results_parser.add_argument(
        "--unit",
        type=str,
        default="kcal/mol",
        choices={"kcal/mol", "Hartree"},
        help="convert to UNIT",
    )
    results_parser.add_argument(
        "--thermo",
        default="free_energy",
        help="Which thermodynamic quantity to use (default is 'free-energy'=='RRHO')",
        choices=[
            "energy",
            "enthalpy",
            "free_energy",
            "RRHO",
            "QRRHO",
            "QHARM",
        ],
    )
    results_parser.add_argument(
        "--temp",
        type=float,
        default=None,
        help="Temperature (K) to use (if different from config specification)",
    )
    results_parser.add_argument(
        "-w0",
        "--frequency-cutoff",
        type=float,
        default=100.0,
        dest="w0",
        help="cutoff frequency for quasi free energy corrections (1/cm)\nDefault: 100 cm^-1",
    )
    results_parser.add_argument(
        "--cache",
        type=str,
        default="results.cache",
        metavar="FILENAME",
        help="Where to save (if file doesn't exist) / load (if file does exist) cached job output data",
    )
    results_parser.add_argument(
        "--reload",
        action="store_true",
        help="Clear the current cache file and reload output data",
    )
    results_parser.add_argument(
        "--step", type=float, nargs="+", help="Use only data from this step"
    )


def plot_arguments(plot_parser):
    plot_parser.add_argument("--title", nargs="*", help="The title(s) to use")
    plot_parser.add_argument(
        "--save", action="store_true", help="Save the plot as CHANGE.tiff"
    )


def output_arguments(command_parser):
    command_parser.add_argument(
        "-csv", "--csv", action="store_true", help="Use csv format"
    )
    command_parser.add_argument(
        "-of",
        "--outfile",
        nargs=1,
        help="Save to file instead of printing to STDOUT",
    )


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        description="For help with a specific command use 'Aaron <command> --help'",
    )

    # Subparsers for commands
    command = parser.add_subparsers(title="commands", dest="command")

    command_parser = command.add_parser(
        "run", help="Run Aaron workflow (default command)"
    )
    add_common_arguments(command_parser)
    run_arguments(command_parser)

    command_parser = command.add_parser(
        "update",
        help="Force update workflows. Only use if there's a problem with the FireWorks database, otherwise use `AaronJr run --dry CONFIG`.",
    )
    add_common_arguments(command_parser)
    update_arguments(command_parser)

    command_parser = command.add_parser(
        "results", help="Show computational results summary"
    )
    add_common_arguments(command_parser)
    results_arguments(command_parser)
    output_arguments(command_parser)

    command_parser = command.add_parser(
        "plot", help="plot reaction energy diagram"
    )
    add_common_arguments(command_parser)
    results_arguments(command_parser)
    plot_arguments(command_parser)

    # 'resources' specific options
    command_parser = command.add_parser(
        "resources", help="Show resource usage summary"
    )
    add_common_arguments(command_parser)
    resources_arguments(command_parser)
    output_arguments(command_parser)

    args = parser.parse_args()
    main(args)
